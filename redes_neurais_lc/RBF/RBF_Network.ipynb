{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/valmirf/redes_neurais_lc/blob/main/RBF/RBF_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A0GQWDGtrpX"
   },
   "source": [
    "# Rede Neural de Base Radial (RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7W_VNPAkFcO"
   },
   "source": [
    "As redes RBF são redes de alimentação direta (feedforward) consistindo de três camadas:\n",
    "\n",
    "\n",
    "1.   **Camada de entrada**: propaga os estímulos\n",
    "2.   **Camada escondida**: Unidades de processamento localmente sintonizáveis, utilizando mapeamento não linear.\n",
    "3.   **Camada de saída**: Unidades de processamento lineares.\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "**O treinamento dessa rede ocorre de forma híbrida**, combinando aprendizagem não supervisionada (ANS) com a supervisionada(AS). Isso ocorre, pois em geral não se sabe quais saídas se desejam para a camada escondida. Sendo assim, a distribuição de trabalhos ocorre:\n",
    "*   **ANS**: Treina a camada escondida definindo seus parâmetros livres (centros, larguras dos campos receptivos e pesos).\n",
    "*   **AS**: Determina os valores dos pesos entre as camadas escondidas e de saída, considerando constantes os parâmetros já definidos.\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "**O aprendizado consiste em** determinar os valores para:\n",
    "*   centro das funções de base radial,\n",
    "*   largura das funções,\n",
    "*   pesos da camada de saída.\n",
    "\n",
    "\n",
    "Além disso, para cada neurônio da camada escondida, ele computa uma função de base radial.\n",
    "\n",
    "\n",
    "Os passos necessários são:\n",
    "1.   Utilizar um algoritmo ANS para encontrar os centros (protótipo para um cluster) das RBF;\n",
    "2.   Utilizar métodos heurísticos para determinar a largura (área de influência de um cluster) de cada função;\n",
    "3.   Utilizar um AS para determinar os pesos da camada de saída da rede."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOIor4J3PFBL"
   },
   "source": [
    "1ª Etapa: Inicialização dos grupos com K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHWuP3AXjvq1",
    "outputId": "f253425c-80a0-4f36-e608-d4b6fa0b85b2"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/valmirf/redes_neurais_bcc.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ulVaA8RPSwo"
   },
   "source": [
    "Definição da função de base radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YeqYYe9hPY4v"
   },
   "outputs": [],
   "source": [
    "#função de base radial gaussiana\n",
    "def rbfGaussiana(x, c, s):\n",
    "    return np.exp(-((x-c)**2)/(2 * s**2))\n",
    "\n",
    "#funcao de base quadratica inversa\n",
    "def rbfMultiquadInv(x, c, s):\n",
    "    return 1/np.sqrt((x-c)**2 + (s)**2)\n",
    "\n",
    "#função de cálculo da largura do campo receptivo em que se repete o mesmo valor pra todos os neurônios\n",
    "def computeEqualStds(centers,k):\n",
    "  dist = [np.sqrt(np.sum((c1 - c2) ** 2)) for c1 in centers for c2 in centers]\n",
    "  dMax = np.max(dist)\n",
    "  stds = np.repeat(dMax / np.sqrt(2 * k), k)\n",
    "  return stds\n",
    "\n",
    "\n",
    "#funcao de calculo de largura de campo receptivo onde cada neuronio tem valor diferente\n",
    "def computeNotEqualStds(centers, k):\n",
    "    stds = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        dist = np.ones(k)*(10**10)\n",
    "        for j in range(k):\n",
    "            if (i != j):\n",
    "                dist[j] = dist[j] +  np.linalg.norm(centers[i] - centers[j])\n",
    "        dMin = np.min(dist)\n",
    "        stds[i] = dMin/k\n",
    "    return stds\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkrFhNWPLq41"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52oUNimoPuK3"
   },
   "source": [
    "2ª Etapa - Treinamento de uma Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RGdrOhYfPzBu"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "class RBFNet(object):\n",
    "    \"\"\"Implementation of a Radial Basis Function Network\"\"\"\n",
    "\n",
    "    def __init__(self, k=4, attnumber=18, lr=0.01, epochs=100, rbf=rbfGaussiana, computeStds=computeEqualStds):\n",
    "        self.k = k  # grupos ou numero de neuronios na camada escondida\n",
    "        self.lr = lr # taxa de aprendizagem\n",
    "        self.epochs = epochs  # número de iterações\n",
    "        self.rbf = rbf # função de base radial\n",
    "        self.computeStds = computeStds  #função de cálculo da largura do campo receptivo\n",
    "\n",
    "\n",
    "        self.w = np.random.randn(self.k,attnumber)\n",
    "        self.b = np.random.randn(1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.stds = []\n",
    "        #K-Means pra pegar os centros inicias \n",
    "        #1º parâmetro da rede RBF\n",
    "        kmeans = KMeans(\n",
    "            n_clusters=self.k, init='random',\n",
    "            n_init=10, max_iter=300).fit(X)\n",
    "        self.centers = kmeans.cluster_centers_\n",
    "        #print('centers: ', self.centers)\n",
    "        \n",
    "        #Cálculo la dargura do campo receptivo\n",
    "        #2º parâmetro da rede RBF\n",
    "        self.stds = self.computeStds(self.centers,self.k)\n",
    "        # training\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X.shape[0]):\n",
    "                # forward pass\n",
    "                #calcula a saída de cada neurônio da função de base radial\n",
    "                phi = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
    "                #calcula somatório do produto da saída da função de base radial e os pesos\n",
    "                F = phi.T.dot(self.w)\n",
    "                F = np.sum(F) + self.b\n",
    "                #saída da rede\n",
    "                out = self.sigmoid(F)\n",
    "                out = 0 if out < 0.5 else 1\n",
    "                \n",
    "                #função de perda \n",
    "                loss = (y[i] - out).flatten() ** 2\n",
    "                #print('Loss: {0:.2f}'.format(loss[0]))\n",
    "\n",
    "                #cálculo do erro\n",
    "                error = (y[i] - out).flatten()\n",
    "                #atualização dos pesos\n",
    "                #3º Parâmetro da rede \n",
    "                self.w = self.w + self.lr * error * phi \n",
    "                self.b = self.b + self.lr * error\n",
    "\n",
    "    #calcula saída da rede RBF com a rede treinada\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        error = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            a = np.array([self.rbf(X[i], c, s) for c, s, in zip(self.centers, self.stds)])\n",
    "            F = a.T.dot(self.w)\n",
    "            #print('F: ' + str(F))\n",
    "            F = np.sum(F) + self.b\n",
    "            #print('F2: ' + str(F))\n",
    "            out = self.sigmoid(F)\n",
    "            out = 0 if out < 0.5 else 1\n",
    "            y_pred.append(out)\n",
    "\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    # Função de Ativação Sigmóide\n",
    "    def sigmoid(self, net):\n",
    "      return 1.0/(1.0+np.exp(-net))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWNpEtxSW46Q"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Isto está formatado como código\n",
    "```\n",
    "\n",
    "# Executando a rede neural RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P75CdFJ4W7mU",
    "outputId": "4c4a3a0f-f5a0-4206-d2b3-70aa4fe0eed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 neuronios na camada escondida:\n",
      "error: 20/42\n",
      "error:  47.61904761904761\n",
      "3 neuronios na camada escondida:\n",
      "error: 20/42\n",
      "error:  47.61904761904761\n",
      "4 neuronios na camada escondida:\n",
      "error: 20/42\n",
      "error:  47.61904761904761\n",
      "5 neuronios na camada escondida:\n",
      "error: 20/42\n",
      "error:  47.61904761904761\n"
     ]
    }
   ],
   "source": [
    "# Neste código vou utilizar o pandas, framework amplamente utilizado pra lidar com dados\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#carrega a base de dados e retorna conjuntos de treinamento e teste\n",
    "def load_data():\n",
    "#     url = 'redes_neurais_bcc/RBF/sonar.csv'\n",
    "    url = 'sonar.csv'\n",
    "    df = pd.read_csv(url)\n",
    "    #remove a ultima coluna (dados)\n",
    "    data = df[df.columns[:-1]]\n",
    "    #normaliza os dados\n",
    "    normalized_data = (data - data.min()) / (data.max() - data.min())\n",
    "    #retorna a última coluna (rótulos)\n",
    "    labels = df[df.columns[-1]]\n",
    "    #separa em conjunto de treinamento e teste com seus respectivos rótulos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(normalized_data, labels, test_size=0.2, random_state=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#chama função que carrega base de dados\n",
    "training_inputs, test_inputs, training_labels, test_labels = load_data()\n",
    "\n",
    "#transforma rótulos do conjunto de treinamento em numeros pra calculo do erro\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(training_labels.values)\n",
    "training_labels_transformed = le.transform(training_labels.values)\n",
    "\n",
    "# #chama RBF\n",
    "# rbfnet = RBFNet(lr=1e-2, attnumber=60, k=12, computeStds=computeEqualStds)\n",
    "# rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
    "\n",
    "# #transforma rótulos do conjunto de teste em numeros pra calculo do erro\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(test_labels.values)\n",
    "# test_labels_transformed = le.transform(test_labels.values)\n",
    "\n",
    "# y_pred = rbfnet.predict(test_labels_transformed)\n",
    "# errorabs = abs(test_labels_transformed-y_pred)\n",
    "\n",
    "# print('error: ' + str(np.sum(errorabs)) + '/' + str(len(test_labels_transformed))) \n",
    "# print('error: ', np.sum(errorabs)/len(test_labels_transformed)*100)\n",
    "\n",
    "def rbfKvalue(val = 2):\n",
    "    #chama RBF\n",
    "    rbfnet = RBFNet(lr=1e-2, attnumber=60, k=val, epochs=100, rbf=rbfMultiquadInv, computeStds=computeNotEqualStds)\n",
    "    rbfnet.fit(training_inputs.values, training_labels_transformed)\n",
    "\n",
    "    #transforma rótulos do conjunto de teste em numeros pra calculo do erro\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(test_labels.values)\n",
    "    test_labels_transformed = le.transform(test_labels.values)\n",
    "\n",
    "    y_pred = rbfnet.predict(test_labels_transformed)\n",
    "    errorabs = abs(test_labels_transformed-y_pred)\n",
    "\n",
    "    print('error: ' + str(np.sum(errorabs)) + '/' + str(len(test_labels_transformed))) \n",
    "    print('error: ', np.sum(errorabs)/len(test_labels_transformed)*100)\n",
    "\n",
    "\n",
    "print(\"2 neuronios na camada escondida:\")\n",
    "rbfKvalue(2)\n",
    "print(\"3 neuronios na camada escondida:\")\n",
    "rbfKvalue(3)\n",
    "print(\"4 neuronios na camada escondida:\")\n",
    "rbfKvalue(4)\n",
    "print(\"5 neuronios na camada escondida:\")\n",
    "rbfKvalue(5)\n",
    "# print(\"15 neuronios na camada escondida:\")\n",
    "# rbfKvalue(15)\n",
    "# print(\"1 neuronios na camada escondida:\")\n",
    "# rbfKvalue(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLO2Gq4Jtso3"
   },
   "source": [
    "# Descrição Mini Projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOrl4i0areNo"
   },
   "source": [
    "Utilizando o código acima, modifique a última seção (Executando com Base de Dados) para que ele seja executado com a base de dados do arquivo iris.csv.\n",
    "\n",
    "\n",
    "1- Calcular a quantidade de neurônios escondidos:\n",
    "\n",
    "a) 2 taxa de erro 20/42\n",
    "\n",
    "b) 3 taxa de erro 20/42\n",
    "\n",
    "c) 4 taxa de erro 20/42\n",
    "\n",
    "d) 5 taxa de erro 20/42\n",
    "\n",
    "Qual foi a melhor configuração? Avaliaria um outro valor?\n",
    "\n",
    "As melhores configurações foram 4 e 5, que em mais vezes não apresentou nenhum erro. Avaliaria com somente um neurônio na camada escondida.\n",
    "\n",
    "2- Utilizando a melhor configuração da questão anterior, calcular a taxa de erro usando uma das outras maneiras de retorno da largura do campo receptivo da função de base radial. Altere o código de forma que cada neurônio possua sua própria largura.\n",
    "20/42\n",
    "\n",
    "3- Modifique a função de base radial implementada (Gaussiana), para a Multiquadrática inversa e calcule a taxa de erro para as configurações das questões anteriores. \n",
    "20/42\n",
    "\n",
    "Qual foi a melhor configuração?\n",
    "\n",
    "o quinto da primeira questão, que conseguiu maior precisão mais vezes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "RBF Network",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
